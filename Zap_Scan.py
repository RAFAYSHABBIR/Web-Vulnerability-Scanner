from zapv2 import ZAPv2
import time
from urllib.parse import urlparse
from bs4 import BeautifulSoup
import shutil
import os
from flask import Flask
import Scaping
#target URL for scan 
# target = 'https://www.coursera.org/'
# apikey = 'iqppmfob7ajcfka3hvo5kuotcj
def scanning(target):
    # Enter your own API
    apikey = 't7tgmndf65pml2arbf8016ioam'
    # apikey = '5ck2b32he754s63rsq4cnpbkt2'

    zap = ZAPv2(apikey=apikey, proxies=
        {'http':'http://localhost:8080'}
    )
    zap.urlopen(target)

    # Spider Scan
    zap.spider.scan(url=target, maxchildren=5, recurse= True, subtreeonly= False, apikey=apikey)
    time.sleep(5)
    while(int(zap.spider.status())<100):
        print(f"Spider progrssing %: {zap.ascan.status()}")
        time.sleep(5)
    print("spider completed")


    #Passive scan
    # while(int(zap.pscan.records_to_scan)<1000):
        # print("Pscan records:"+zap.pscan.records_to_scan)
        # time.sleep(5)
    # print("Pscan completed")
    
    #HTML Report
    with open('report.html','w') as f:
        f.write(zap.core.htmlreport(apikey=apikey))
        
    # Extracting domain name from URL
    domain = urlparse(target).netloc
    print(domain) # --> www.example.test

    import nmap3
    nmap = nmap3.Nmap()
    result = nmap.nmap_version_detection(domain, args="-T4 -p 79-81 -sV -vv --script vulners -o templates/reportnmap.html")
    print(result)
    with open('templates/reportnmap.html','a') as outfile:
        with open('report.html') as infile:
            outfile.write(infile.read())

    # soup_original_1 = BeautifulSoup(''.join(open('report.html')))
    # soup_original_2 = BeautifulSoup(''.join(open('reportnmap.html')))
    # 
    # for element in soup_original_2.body:
        # soup_original_1.body.append(element)

    # src_path = r"C:/Users/Sajid/Desktop/Website_Vul/reportnmap.html"
    # dst_path = r"C:/Users/Sajid/Desktop/Website_Vul/templates/reportnmap.html"
    # shutil.move(src_path, dst_path)
    # path = os.getcwd()
    # template_dir = os.path.abspath(path)
    # app = Flask(__name__, template_folder = template_dir)
    Scaping.Scraping()
 # scanning(target)